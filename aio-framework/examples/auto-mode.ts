/**
 * Example: Auto Mode - T·ª± ƒë·ªông ch·ªçn provider/model v√† fallback
 */

import { AIO } from "../src/index.js";

async function main() {
  // Kh·ªüi t·∫°o AIO v·ªõi auto mode
  const aio = new AIO({
    providers: [
      {
        provider: "groq",
        apiKeys: [
          {
            key: process.env.GROQ_API_KEY || "your-groq-key-here",
            priority: 10,
          },
        ],
        models: [{ modelId: "openai/gpt-oss-120b", priority: 10 }],
        priority: 100, // Groq ∆∞u ti√™n cao nh·∫•t
      },
      {
        provider: "google-ai",
        apiKeys: [
          {
            key: process.env.GOOGLE_AI_API_KEY || "your-google-key-here",
          },
        ],
        models: [{ modelId: "gemini-3-flash-preview" }],
        priority: 80, // Gemini fallback
      },
    ],
    autoMode: true, // B·∫≠t auto mode
  });

  console.log("üöÄ AIO Framework - Auto Mode Example\n");

  // Kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh provider/model
  // AIO s·∫Ω t·ª± ƒë·ªông ch·ªçn theo priority v√† fallback n·∫øu fail
  console.log("üì§ Sending request (auto mode)...");
  const response = await aio.chatCompletion({
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: "Explain quantum computing in simple terms." },
    ],
    temperature: 0.7,
    max_tokens: 200,
  });

  console.log("\n‚úÖ Response:");
  console.log(`Provider: ${response.provider}`);
  console.log(`Model: ${response.model}`);
  console.log(`Content: ${response.choices[0].message.content}`);

  if (response.auto_fallback) {
    console.log("\n‚ö†Ô∏è Fallback occurred:");
    console.log(
      `Original: ${response.auto_fallback.original_provider}:${response.auto_fallback.original_model}`
    );
    console.log(
      `Final: ${response.auto_fallback.final_provider}:${response.auto_fallback.final_model}`
    );
    console.log(`Fallback count: ${response.auto_fallback.fallback_count}`);
  }
}

main().catch(console.error);
