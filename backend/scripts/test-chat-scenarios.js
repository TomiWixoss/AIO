#!/usr/bin/env node

/**
 * Script test Ä‘áº§y Ä‘á»§ cÃ¡c trÆ°á»ng há»£p chat
 */

const BASE_URL = process.env.BASE_URL || "http://localhost:4000";

const colors = {
  reset: "\x1b[0m",
  green: "\x1b[32m",
  red: "\x1b[31m",
  yellow: "\x1b[33m",
  cyan: "\x1b[36m",
};

function log(message, color = "reset") {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

async function getToken() {
  const response = await fetch(`${BASE_URL}/auth/login`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      email: "admin@localhost",
      password: "admin123",
    }),
  });
  const data = await response.json();
  return data.data.token;
}

function generateSessionKey() {
  return crypto.randomUUID();
}

async function chat(token, body) {
  const response = await fetch(`${BASE_URL}/chat`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${token}`,
    },
    body: JSON.stringify(body),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || "Request failed");
  }

  return await response.json();
}

async function test1_NoSystemPrompt(token) {
  log("\n=== TEST 1: No System Prompt ===", "cyan");
  const sessionKey = generateSessionKey();

  const response = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "What is 2+2?",
    session_key: sessionKey,
  });

  const answer = response.choices[0].message.content;
  log(`âœ“ Response: ${answer}`, "green");

  if (answer.includes("4")) {
    log("âœ“ PASSED: Correct answer", "green");
    return true;
  } else {
    log("âœ— FAILED: Wrong answer", "red");
    return false;
  }
}

async function test2_WithSystemPrompt(token) {
  log("\n=== TEST 2: With System Prompt (Vietnamese) ===", "cyan");
  const sessionKey = generateSessionKey();

  const response = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "Hello, what is your name?",
    system_prompt: "You MUST respond in Vietnamese language only.",
    session_key: sessionKey,
  });

  const answer = response.choices[0].message.content;
  log(`âœ“ Response: ${answer}`, "green");

  // Check if response contains Vietnamese characters
  const hasVietnamese =
    /[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]/i.test(
      answer
    );

  if (hasVietnamese) {
    log("âœ“ PASSED: Response in Vietnamese", "green");
    return true;
  } else {
    log("âœ— FAILED: Response not in Vietnamese", "red");
    return false;
  }
}

async function test3_MultiTurnHistory(token) {
  log("\n=== TEST 3: Multi-turn History ===", "cyan");
  const sessionKey = generateSessionKey();

  // Turn 1
  log("Turn 1: My name is Alice", "yellow");
  const response1 = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "My name is Alice",
    session_key: sessionKey,
  });
  log(`Response: ${response1.choices[0].message.content}`, "green");

  // Wait a bit
  await new Promise((resolve) => setTimeout(resolve, 1000));

  // Turn 2
  log("\nTurn 2: What is my name?", "yellow");
  const response2 = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "What is my name?",
    session_key: sessionKey,
  });

  const answer = response2.choices[0].message.content;
  log(`Response: ${answer}`, "green");

  if (answer.toLowerCase().includes("alice")) {
    log("âœ“ PASSED: Remembered name from history", "green");
    return true;
  } else {
    log("âœ— FAILED: Did not remember name", "red");
    return false;
  }
}

async function test4_HistoryWithSystemPrompt(token) {
  log("\n=== TEST 4: History + System Prompt ===", "cyan");
  const sessionKey = generateSessionKey();

  // Turn 1
  log("Turn 1: TÃªn tÃ´i lÃ  Minh (with Vietnamese system prompt)", "yellow");
  const response1 = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "TÃªn tÃ´i lÃ  Minh",
    system_prompt: "Báº¡n lÃ  trá»£ lÃ½ AI. LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.",
    session_key: sessionKey,
  });
  log(`Response: ${response1.choices[0].message.content}`, "green");

  await new Promise((resolve) => setTimeout(resolve, 1000));

  // Turn 2 - no system prompt in second turn
  log("\nTurn 2: TÃªn tÃ´i lÃ  gÃ¬? (no system prompt)", "yellow");
  const response2 = await chat(token, {
    provider: "openrouter",
    model: "meta-llama/llama-3.3-70b-instruct:free",
    message: "TÃªn tÃ´i lÃ  gÃ¬?",
    session_key: sessionKey,
  });

  const answer = response2.choices[0].message.content;
  log(`Response: ${answer}`, "green");

  const hasVietnamese =
    /[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]/i.test(
      answer
    );
  const hasMinhName = answer.toLowerCase().includes("minh");

  if (hasVietnamese && hasMinhName) {
    log("âœ“ PASSED: Remembered name and kept Vietnamese", "green");
    return true;
  } else {
    log(`âœ— FAILED: Vietnamese=${hasVietnamese}, HasName=${hasMinhName}`, "red");
    return false;
  }
}

async function test5_DifferentModels(token) {
  log("\n=== TEST 5: Different Models ===", "cyan");
  const models = [
    "meta-llama/llama-3.3-70b-instruct:free",
    "qwen/qwen3-coder:free",
    "mistralai/mistral-small-3.1-24b-instruct:free",
  ];

  let passed = 0;
  for (const model of models) {
    try {
      const sessionKey = generateSessionKey();
      log(`\nTesting: ${model}`, "yellow");

      const response = await chat(token, {
        provider: "openrouter",
        model,
        message: "Say hello in 3 words",
        session_key: sessionKey,
      });

      const answer = response.choices[0].message.content;
      log(`âœ“ Response: ${answer}`, "green");
      passed++;
    } catch (error) {
      log(`âœ— Failed: ${error.message}`, "red");
    }
  }

  if (passed === models.length) {
    log(`\nâœ“ PASSED: All ${models.length} models working`, "green");
    return true;
  } else {
    log(`\nâœ— FAILED: Only ${passed}/${models.length} models working`, "red");
    return false;
  }
}

async function test6_Streaming(token) {
  log("\n=== TEST 6: Streaming ===", "cyan");
  const sessionKey = generateSessionKey();

  try {
    const response = await fetch(`${BASE_URL}/chat`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${token}`,
      },
      body: JSON.stringify({
        provider: "openrouter",
        model: "meta-llama/llama-3.3-70b-instruct:free",
        message: "Count from 1 to 3",
        session_key: sessionKey,
        stream: true,
      }),
    });

    if (!response.ok) {
      throw new Error("Streaming request failed");
    }

    const text = await response.text();
    const chunks = text.split("\n").filter((line) => line.startsWith("data:"));

    log(`âœ“ Received ${chunks.length} chunks`, "green");

    if (chunks.length > 0) {
      log("âœ“ PASSED: Streaming works", "green");
      return true;
    } else {
      log("âœ— FAILED: No chunks received", "red");
      return false;
    }
  } catch (error) {
    log(`âœ— FAILED: ${error.message}`, "red");
    return false;
  }
}

async function main() {
  console.clear();
  log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", "cyan");
  log("â•‘              CHAT SCENARIOS TEST SUITE                     â•‘", "cyan");
  log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", "cyan");
  log(`\nBase URL: ${BASE_URL}\n`, "cyan");

  const startTime = Date.now();
  const results = [];

  try {
    log("ğŸ”‘ Getting auth token...", "yellow");
    const token = await getToken();
    log("âœ“ Token obtained\n", "green");

    // Run all tests
    results.push(await test1_NoSystemPrompt(token));
    await new Promise((resolve) => setTimeout(resolve, 2000));

    results.push(await test2_WithSystemPrompt(token));
    await new Promise((resolve) => setTimeout(resolve, 2000));

    results.push(await test3_MultiTurnHistory(token));
    await new Promise((resolve) => setTimeout(resolve, 2000));

    results.push(await test4_HistoryWithSystemPrompt(token));
    await new Promise((resolve) => setTimeout(resolve, 2000));

    results.push(await test5_DifferentModels(token));
    await new Promise((resolve) => setTimeout(resolve, 2000));

    results.push(await test6_Streaming(token));
  } catch (error) {
    log(`\nâŒ Fatal error: ${error.message}`, "red");
    console.error(error);
    process.exit(1);
  }

  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  const passed = results.filter((r) => r).length;
  const failed = results.filter((r) => !r).length;

  log("\n" + "=".repeat(60), "cyan");
  log("TEST SUMMARY", "cyan");
  log("=".repeat(60), "cyan");
  log(`\nTotal Tests: ${results.length}`, "cyan");
  log(`Passed: ${passed}`, "green");
  log(`Failed: ${failed}`, failed > 0 ? "red" : "green");
  log(`Duration: ${duration}s`, "cyan");

  if (failed === 0) {
    log("\nğŸ‰ All tests passed!", "green");
    process.exit(0);
  } else {
    log("\nâŒ Some tests failed!", "red");
    process.exit(1);
  }
}

main();
