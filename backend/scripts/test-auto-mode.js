// Test Auto Mode - Ch·∫ø ƒë·ªô t·ª± ƒë·ªông ch·ªçn model theo priority v√† fallback
// Ch·∫°y: node scripts/test-auto-mode.js

const API_URL = process.env.API_URL || "http://localhost:4000";

async function testAutoMode() {
  console.log("üß™ Testing Auto Mode...\n");
  console.log("Auto mode s·∫Ω:");
  console.log("  1. Ch·ªçn provider c√≥ priority cao nh·∫•t");
  console.log("  2. Ch·ªçn model c√≥ priority cao nh·∫•t trong provider ƒë√≥");
  console.log("  3. N·∫øu l·ªói ‚Üí fallback sang model ti·∫øp theo");
  console.log(
    "  4. N·∫øu h·∫øt model trong provider ‚Üí chuy·ªÉn sang provider ti·∫øp theo"
  );
  console.log("  5. Kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn fallback\n");

  // Test 1: Chat v·ªõi auto_mode = true
  console.log("1Ô∏è‚É£ Test chat v·ªõi auto_mode = true");
  try {
    const response = await fetch(`${API_URL}/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        provider: "google-ai", // Provider m·∫∑c ƒë·ªãnh (s·∫Ω b·ªã override n·∫øu auto ch·ªçn kh√°c)
        model: "gemini-2.0-flash", // Model m·∫∑c ƒë·ªãnh
        message: "Xin ch√†o! B·∫°n l√† AI n√†o? Tr·∫£ l·ªùi ng·∫Øn g·ªçn.",
        stream: false,
        auto_mode: true, // B·∫¨T CH·∫æ ƒê·ªò AUTO
      }),
    });

    const data = await response.json();

    if (data.error) {
      console.log("‚ùå Error:", data.error);
    } else {
      console.log("‚úÖ Response received!");
      console.log("   Provider:", data.provider);
      console.log("   Model:", data.model);

      if (data.auto_fallback) {
        console.log("   üîÑ Auto Fallback Info:");
        console.log(
          "     - Original:",
          data.auto_fallback.original_provider,
          "/",
          data.auto_fallback.original_model
        );
        console.log(
          "     - Final:",
          data.auto_fallback.final_provider,
          "/",
          data.auto_fallback.final_model
        );
        console.log(
          "     - Fallback count:",
          data.auto_fallback.fallback_count
        );
      } else {
        console.log("   ‚ú® Kh√¥ng c·∫ßn fallback - model ƒë·∫ßu ti√™n ho·∫°t ƒë·ªông t·ªët");
      }

      console.log(
        "   Content:",
        data.choices?.[0]?.message?.content?.substring(0, 100) + "..."
      );
    }
  } catch (error) {
    console.log("‚ùå Error:", error.message);
  }

  // Test 2: Stream v·ªõi auto_mode = true
  console.log("\n2Ô∏è‚É£ Test streaming v·ªõi auto_mode = true");
  try {
    const response = await fetch(`${API_URL}/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        provider: "google-ai",
        model: "gemini-2.0-flash",
        message: "K·ªÉ m·ªôt c√¢u chuy·ªán ng·∫Øn 2 c√¢u",
        stream: true,
        auto_mode: true,
      }),
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let content = "";
    let autoInfo = null;

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split("\n");

      for (const line of lines) {
        if (line.startsWith("data: ")) {
          const data = line.slice(6);
          if (data === "[DONE]") continue;

          try {
            const parsed = JSON.parse(data);
            if (parsed.auto_fallback) {
              autoInfo = parsed.auto_fallback;
            }
            const delta = parsed.choices?.[0]?.delta?.content;
            if (delta) {
              content += delta;
              process.stdout.write(delta);
            }
          } catch {}
        }
      }
    }

    console.log("\n\n‚úÖ Stream completed!");
    if (autoInfo) {
      console.log("   üîÑ Auto Fallback Info:");
      console.log("     - Fallback count:", autoInfo.fallback_count);
    }
    console.log("   Total length:", content.length, "chars");
  } catch (error) {
    console.log("‚ùå Error:", error.message);
  }

  // Test 3: So s√°nh v·ªõi auto_mode = false
  console.log("\n3Ô∏è‚É£ Test chat v·ªõi auto_mode = false (ch·∫ø ƒë·ªô th∆∞·ªùng)");
  try {
    const response = await fetch(`${API_URL}/chat`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        provider: "google-ai",
        model: "gemini-2.0-flash",
        message: "Xin ch√†o!",
        stream: false,
        auto_mode: false, // T·∫ÆT CH·∫æ ƒê·ªò AUTO
      }),
    });

    const data = await response.json();

    if (data.error) {
      console.log("‚ùå Error:", data.error);
    } else {
      console.log("‚úÖ Response received!");
      console.log("   Provider:", data.provider);
      console.log("   Model:", data.model);
      console.log(
        "   auto_fallback:",
        data.auto_fallback ? "c√≥" : "kh√¥ng (nh∆∞ mong ƒë·ª£i)"
      );
    }
  } catch (error) {
    console.log("‚ùå Error:", error.message);
  }

  console.log("\n‚úÖ Auto mode tests completed!");
}

testAutoMode().catch(console.error);
